{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a4e788-9591-4faf-a464-8a2340f9a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from difflib import SequenceMatcher\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45b9d09f-d1f5-40f3-bfa4-caecfd4b797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = ET.parse('./papers/cs_tei/2012.02107v1.tei.xml')\n",
    "root1 = tree1.getroot()\n",
    "\n",
    "tree2 = ET.parse('./papers/cs_tei/2012.02107v2.tei.xml')\n",
    "root2 = tree2.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8395cd2-7139-496c-998d-867c15baf538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{http://www.tei-c.org/ns/1.0}teiHeader {'{http://www.w3.org/XML/1998/namespace}lang': 'en'}\n",
      "{http://www.tei-c.org/ns/1.0}facsimile {}\n",
      "{http://www.tei-c.org/ns/1.0}text {'{http://www.w3.org/XML/1998/namespace}lang': 'en'}\n"
     ]
    }
   ],
   "source": [
    "for child in root1:\n",
    "    print(child.tag, child.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9cf6bdd-4da5-4b87-8f93-971ae4025a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET.tostring(root1[1], encoding='unicode') == ET.tostring(root2[1], encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "beea7d30-69b3-4170-a80a-800b14b5ba16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET.tostring(root1[1], encoding='unicode') == ET.tostring(root2[1], encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b03ec89f-6de6-4a9c-b822-e2a2d2d61a02",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<ns0:teiHeader xmlns:ns0=\"http://www.tei-c.org/ns/1.0\" xml:lang=\"en\">\\n\\t\\t<ns0:fileDesc>\\n\\t\\t\\t<ns0:titleStmt>\\n\\t\\t\\t\\t<ns0:title level=\"a\" type=\"main\">Perfect Matchings in Õ(n 1.5 ) Time in Regular Bipartite Graphs</ns0:title>\\n\\t\\t\\t</ns0:titleStmt>\\n\\t\\t\\t<ns0:publicationStmt>\\n\\t\\t\\t\\t<ns0:publisher />\\n\\t\\t\\t\\t<ns0:availability status=\"unknown\"><ns0:licence /></ns0:availability>\\n\\t\\t\\t\\t<ns0:date type=\"published\" when=\"2009-07-30\">30 Jul 2009</ns0:date>\\n\\t\\t\\t</ns0:publicationStmt>\\n\\t\\t\\t<ns0:sourceDesc>\\n\\t\\t\\t\\t<ns0:biblStruct>\\n\\t\\t\\t\\t\\t<ns0:analytic>\\n\\t\\t\\t\\t\\t\\t<ns0:author>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:persName coords=\"1,159.94,145.24,59.44,10.37;1,219.38,143.24,1.41,6.99\"><ns0:forename type=\"first\">Ashish</ns0:forename><ns0:surname>Goel</ns0:surname></ns0:persName>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:email>ashishg@stanford.edu</ns0:email>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:affiliation key=\"aff0\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<ns0:orgName type=\"department\">Departments of Management Science and Engineering and (by courtesy) Computer Science</ns0:orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<ns0:orgName type=\"institution\">Stanford University</ns0:orgName>\\n\\t\\t\\t\\t\\t\\t\\t</ns0:affiliation>\\n\\t\\t\\t\\t\\t\\t</ns0:author>\\n\\t\\t\\t\\t\\t\\t<ns0:author>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:persName coords=\"1,257.23,145.24,86.47,10.37;1,343.70,143.24,1.88,6.99\"><ns0:forename type=\"first\">Michael</ns0:forename><ns0:surname>Kapralov</ns0:surname></ns0:persName>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:email>kapralov@stanford.edu.re-search</ns0:email>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:affiliation key=\"aff1\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<ns0:orgName type=\"department\">Institute for Computational and Mathematical Engineering</ns0:orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<ns0:orgName type=\"institution\">Stanford University</ns0:orgName>\\n\\t\\t\\t\\t\\t\\t\\t</ns0:affiliation>\\n\\t\\t\\t\\t\\t\\t</ns0:author>\\n\\t\\t\\t\\t\\t\\t<ns0:author>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:persName coords=\"1,381.54,145.24,77.72,10.37;1,459.26,143.24,1.88,6.99\"><ns0:forename type=\"first\">Sanjeev</ns0:forename><ns0:surname>Khanna</ns0:surname></ns0:persName>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:email>sanjeev@cis.upenn.edu</ns0:email>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:affiliation key=\"aff2\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<ns0:orgName type=\"department\">Department of Computer and Information Science</ns0:orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<ns0:orgName type=\"institution\">University of Pennsylvania</ns0:orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<ns0:address>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<ns0:settlement>Philadelphia</ns0:settlement>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t<ns0:region>PA</ns0:region>\\n\\t\\t\\t\\t\\t\\t\\t\\t</ns0:address>\\n\\t\\t\\t\\t\\t\\t\\t</ns0:affiliation>\\n\\t\\t\\t\\t\\t\\t</ns0:author>\\n\\t\\t\\t\\t\\t\\t<ns0:title level=\"a\" type=\"main\">Perfect Matchings in Õ(n 1.5 ) Time in Regular Bipartite Graphs</ns0:title>\\n\\t\\t\\t\\t\\t</ns0:analytic>\\n\\t\\t\\t\\t\\t<ns0:monogr>\\n\\t\\t\\t\\t\\t\\t<ns0:imprint>\\n\\t\\t\\t\\t\\t\\t\\t<ns0:date type=\"published\" when=\"2009-07-30\">30 Jul 2009</ns0:date>\\n\\t\\t\\t\\t\\t\\t</ns0:imprint>\\n\\t\\t\\t\\t\\t</ns0:monogr>\\n\\t\\t\\t\\t\\t<ns0:idno type=\"MD5\">571F416A9CDEFED6A6E7EA04267BB32F</ns0:idno>\\n\\t\\t\\t\\t\\t<ns0:idno type=\"arXiv\">arXiv:0902.1617v2[cs.DS]</ns0:idno>\\n\\t\\t\\t\\t</ns0:biblStruct>\\n\\t\\t\\t</ns0:sourceDesc>\\n\\t\\t</ns0:fileDesc>\\n\\t\\t<ns0:encodingDesc>\\n\\t\\t\\t<ns0:appInfo>\\n\\t\\t\\t\\t<ns0:application version=\"0.7.2-SNAPSHOT\" ident=\"GROBID\" when=\"2022-09-08T16:36+0000\">\\n\\t\\t\\t\\t\\t<ns0:desc>GROBID - A machine learning software for extracting information from scholarly documents</ns0:desc>\\n\\t\\t\\t\\t\\t<ns0:ref target=\"https://github.com/kermitt2/grobid\" />\\n\\t\\t\\t\\t</ns0:application>\\n\\t\\t\\t</ns0:appInfo>\\n\\t\\t</ns0:encodingDesc>\\n\\t\\t<ns0:profileDesc>\\n\\t\\t\\t<ns0:abstract>\\n<ns0:div><ns0:p>We consider the well-studied problem of finding a perfect matching in d-regular bipartite graphs with 2n vertices and m = nd edges. While the best-known algorithm for general bipartite graphs (due to Hopcroft and Karp) takes O(m √ n) time, in regular bipartite graphs, a perfect matching is known to be computable in O(m) time. Very recently, the O(m) bound was improved to O(min{m, n 2.5 ln n d }) expected time, an expression that is bounded by Õ(n 1.75 ). In this paper, we further improve this result by giving an O(min{m, n 2 ln 3 n d }) expected time algorithm for finding a perfect matching in regular bipartite graphs; as a function of n alone, the algorithm takes expected time O((n ln n) 1.5 ).</ns0:p><ns0:p>To obtain this result, we design and analyze a two-stage sampling scheme that reduces the problem of finding a perfect matching in a regular bipartite graph to the same problem on a subsampled bipartite graph with O(n ln n) edges. The first-stage is a sub-linear time uniform sampling that reduces the size of the input graph while maintaining certain structural properties of the original graph. The second-stage is a non-uniform sampling that takes linear-time (on the reduced graph) and outputs a graph with O(n ln n) edges, while preserving a matching with high probability. This matching is then recovered using the Hopcroft-Karp algorithm. While the standard analysis of Hopcroft-Karp also gives us an Õ(n 1.5 ) running time, we present a tighter analysis for our special case that results in the stronger Õ(min{m, n 2 d }) time mentioned earlier.</ns0:p><ns0:p>Our proof of correctness of this sampling scheme uses a new correspondence theorem between cuts and Hall\\'s theorem \"witnesses\" for a perfect matching in a bipartite graph that we prove. We believe this theorem may be of independent interest; as another example application, we show that a perfect matching in the support of an n × n doubly stochastic matrix with m non-zero entries can be found in expected time Õ(m + n 1.5 ).</ns0:p></ns0:div>\\n\\t\\t\\t</ns0:abstract>\\n\\t\\t</ns0:profileDesc>\\n\\t</ns0:teiHeader>\\n\\t'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET.tostring(root2[0], encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9d77c43-8545-4264-b193-8411ed0fffac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = SequenceMatcher(None, ET.tostring(root1[1], encoding='unicode'), ET.tostring(root2[1], encoding='unicode'))\n",
    "m.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9baaed81-89ca-4e32-bb07-f964bb74e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse(\"./papers/cs_xml/2002.06406v2.tei.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c86edb-9c1e-4f66-bad9-b45a81e65534",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ce9e9b-09b5-4510-8f00-5dbd347513d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<text xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\">\\n\\t\\t<body>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><p>prior work based on a passage in the text. This text passage, usually called the citation context, can be of different lengths, ranging from a phrase or sentence up to a whole document.</p><p>Works on global recommendations, that is, citations for the entire paper, have been carried out by <ref type=\"bibr\" target=\"#b29\">[30]</ref>, <ref type=\"bibr\" target=\"#b37\">[38]</ref>, and <ref type=\"bibr\" target=\"#b33\">[34]</ref>, and more recently by <ref type=\"bibr\" target=\"#b0\">[1]</ref>, <ref type=\"bibr\" target=\"#b39\">[40]</ref>, and <ref type=\"bibr\" target=\"#b5\">[6]</ref>. This paper, however, focuses on local citation recommendation, in which a relatively small citation context of 1-3 sentences or 50-100 words is used as input for the recommendation. This type of fine-grained recommendation, sometimes also referred to as context-aware citation recommendation in contemporary research papers, was first explored in <ref type=\"bibr\" target=\"#b15\">[16]</ref> and <ref type=\"bibr\" target=\"#b14\">[15]</ref>.</p><p>Previous works also include personalized approaches, such as <ref type=\"bibr\" target=\"#b8\">[9]</ref> and <ref type=\"bibr\" target=\"#b39\">[40]</ref>, which use author and venue metadata as input and generally obtain better scores in evaluations. However, as explained in <ref type=\"bibr\" target=\"#b0\">[1]</ref>, this is due to the fact that metrics usually favor predictions of obvious citations resulting in better scores, for example citations by the same author. Therefore, this paper will not consider such personalized approaches.</p><p>In this paper, we, first of all, adapt an existing deep-learningbased embedding method to citation recommendation (Hyperdoc2vec by Han et al. <ref type=\"bibr\" target=\"#b13\">[14]</ref>). In addition, we develop several baselines based on topic modeling and classical information retrieval, such as a BM25-based approach, an approach based on Latent Dirichlet Allocation (LDA) <ref type=\"bibr\" target=\"#b2\">[3]</ref>, and one based on paragraph vectors <ref type=\"bibr\" target=\"#b27\">[28]</ref>. Secondly and more importantly, we combine the best-performing recommendation methods of the previous step into a weighted hybrid recommender system for the task of citation recommendation.</p><p>While existing approaches to citation recommendation can be broken down into two steps (see, e.g., <ref type=\"bibr\" target=\"#b0\">[1]</ref>), to the best of our knowledge, no approach has been truly hybrid in nature, i.e., combines results from two different recommendation algorithms. Even though hybrid recommendation approaches have been proposed in other fields, such as for paper recommendation <ref type=\"bibr\" target=\"#b24\">[25]</ref>, the task differs considerably from local citation recommendation, as paper recommendation does not consider citation contexts, leading to different system setups and evaluation setups <ref type=\"bibr\" target=\"#b15\">[16]</ref>.</p><p>To conduct our experiments, we use, for the first time in the area of (local) citation recommendation, the rich Microsoft Academic Graph (MAG) as one of our data sources. We also prepare two auxiliary data sets based on the MAG, with restrictions made on the language and discipline (English and computer science, respectively) -the arXiv data set <ref type=\"bibr\" target=\"#b35\">[36]</ref> and the ACL-ARC data set <ref type=\"bibr\" target=\"#b1\">[2]</ref>. These are mapped back to the MAG and made publicly available. Overall, we create five large-scale evaluation data sets.</p><p>We then evaluate all of our proposed baselines and approaches on the different data sets.</p><p>Overall, we make the following contributions:</p><p>&#8226; We present a hybrid approach to citation recommendation that combines individual approaches to citation recommendation stochastically. 1  &#8226; We prepare two conceptually different data sets (based on citing and cited papers) that will be used in conjunction in an advanced hybrid recommender system. Our advanced hybrid recommender system thus combines several algorithms as well as several data sets. 2  &#8226; We perform an extensive offline evaluation of the developed approaches based on five data sets. Among other data sets, we prepare the MAG (with over 1.6M computer science papers) to this end and provide it online. In addition, we perform a user study. In all evaluations, we can show the superiority of the presented hybrid recommender over its individual components.</p><p>The rest of our paper is structured as follows: After giving an overview of related work on citation recommendation in Section 2, we present our new approaches to citation recommendation in Section 3. Section 4 outlines the evaluation setup and the evaluation results. We conclude in Section 5 with a conclusion and an outlook.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"2\">RELATED WORK</head><p>McNee <ref type=\"bibr\" target=\"#b29\">[30]</ref> in 2002 and Strohman et al. <ref type=\"bibr\" target=\"#b37\">[38]</ref> in 2007 published the first global citation recommendation papers. Since then, various papers on both global and local citation recommendation have been published.</p><p>Local Citation Recommendation The term context-aware recommendation was introduced by He et al. <ref type=\"bibr\" target=\"#b15\">[16]</ref> in 2010, the first paper which covered local recommendation. The authors expanded their model in <ref type=\"bibr\" target=\"#b14\">[15]</ref>. Huang et al. <ref type=\"bibr\" target=\"#b17\">[18]</ref> built upon the idea by translating specific keywords in the contexts (source language) into cited documents (target language), thereby creating a de-facto machine translation system for citation recommendation.</p><p>Huang et al.\\'s paper <ref type=\"bibr\" target=\"#b18\">[19]</ref> was one of the follow-up papers to Huang et al. <ref type=\"bibr\" target=\"#b17\">[18]</ref>. Here, they continued their work on translation models, but added in distributed word representations of the words and cited documents in the citation contexts (see <ref type=\"bibr\" target=\"#b30\">[31]</ref>).</p><p>Embedding-based Approaches Tang et al. <ref type=\"bibr\" target=\"#b38\">[39]</ref> introduced embedding-based approaches to the field of citation recommendation by using TF-IDF vectors to construct cross-language embeddings for local citation recommendation. Jiang et al.\\'s two papers <ref type=\"bibr\" target=\"#b21\">[22,</ref><ref type=\"bibr\" target=\"#b22\">23]</ref> also used embeddings in the context of cross-language global citation recommendation. Similar works were carried out by Cai et al. <ref type=\"bibr\" target=\"#b5\">[6]</ref> and Zhang et al. <ref type=\"bibr\" target=\"#b42\">[43]</ref> in 2018.</p><p>A recent paper on embedding-based neural networks by Han et al. <ref type=\"bibr\" target=\"#b13\">[14]</ref> emphasized content awareness, context awareness, newcomer friendliness, and context intent awareness. Due to these characteristics, we have adapted their approach in this paper.</p><p>Topic Modelling and Information Retrieval Topic modelling and, in particular, Latent Dirichlet Allocation (LDA) <ref type=\"bibr\" target=\"#b2\">[3]</ref> have been used in multiple citation recommendation papers <ref type=\"bibr\" target=\"#b20\">[21,</ref><ref type=\"bibr\" target=\"#b25\">26,</ref><ref type=\"bibr\" target=\"#b28\">29,</ref><ref type=\"bibr\" target=\"#b33\">34]</ref>. In this paper, LDA is used as a baseline.</p><p>Information retrieval techniques such as TF-IDF-based text comparison or BM25 have been studied previously. Duma et al.\\'s two papers <ref type=\"bibr\" target=\"#b6\">[7,</ref><ref type=\"bibr\" target=\"#b7\">8]</ref> treated citation recommendation as an information retrieval task, whereas Ebesu et al. <ref type=\"bibr\" target=\"#b8\">[9]</ref> used BM25 as a simple baseline. We use BM25 in our hybrid recommendation system.</p><p>Hybrid recommender systems Hybrid recommender systems take predictions from two or more disparate recommender systems and combine them in some way.</p><p>Burke <ref type=\"bibr\" target=\"#b3\">[4,</ref><ref type=\"bibr\" target=\"#b4\">5]</ref> provided an excellent introduction and survey about hybrid recommender systems. In the citation recommendation context, Hsiao et al. <ref type=\"bibr\" target=\"#b16\">[17]</ref> used a hybrid recommendation system that combines results from two disparate systems. The authors looked for recommendations from one algorithm and only selected the recommendations of the other algorithm as a last resort. In our paper, however, we create a stochastic (semi-genetic) hybrid recommender system which combines results from multiple sources.</p><p>A two-step process (candidate generation, ranking) to citation recommendation is explored in several papers, including Zarrinkalam <ref type=\"bibr\" target=\"#b41\">[42]</ref>, Bhagavatula et al. <ref type=\"bibr\" target=\"#b0\">[1]</ref>, and McNee <ref type=\"bibr\" target=\"#b29\">[30]</ref>, but these are not hybrid systems per se -as they merely use two different algorithms for candidate generation and ranking. Kanakia et al. <ref type=\"bibr\" target=\"#b24\">[25]</ref> presented a hybrid paper recommender system in which they combined a co-citation-based algorithm and a content-based algorithm. Finally, Rokach et al. <ref type=\"bibr\" target=\"#b34\">[35]</ref> present a hybrid citation recommendation system based on multiple machine learning algorithms whose results are combined by simple averaging. In this paper, we use a semi-genetic algorithm to stochastically combine results from different categories of algorithms while using multiple data sets (concerning citing and cited papers). Due to this incompatibility, a direct comparison to these approaches is not possible.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3\">APPROACH</head><p>In this section, we outline the single approaches used as components as well as the hybrid recommendation algorithm itself.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.1\">Single Approaches</head><p>3.1.1 BM25. Okapi BM25, a bag-of-words algorithm, has been used in citation recommendation approaches both as a pre-filter and as a simple baseline <ref type=\"bibr\" target=\"#b8\">[9]</ref>. BM25 ranks returned documents based on the query terms appearing in each document. However, the specific position of the query terms makes no difference to the ranking algorithm.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.1.2\">Latent Dirichlet Allocation (LDA).</head><p>The main idea behind using LDA <ref type=\"bibr\" target=\"#b2\">[3]</ref> for citation recommendation is to recommend the same citations for the same topics (given by the citation contexts). The topics generated via LDA from the citation context are compared to all topics using cosine similarity. The similarities are sorted in descending order, and the top n similar papers are recommended.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.1.3\">Doc2Vec</head><p>. The literature has many deep learning approaches for citation recommendation, such as RNNs <ref type=\"bibr\" target=\"#b26\">[27,</ref><ref type=\"bibr\" target=\"#b39\">40]</ref> and CNNs <ref type=\"bibr\" target=\"#b8\">[9,</ref><ref type=\"bibr\" target=\"#b40\">41]</ref>. In contrast, embedding-based approaches need considerably less time and resources to train while still achieving reasonable results in recommendation tasks <ref type=\"bibr\" target=\"#b13\">[14]</ref>. One embedding approach is doc2vec <ref type=\"bibr\" target=\"#b27\">[28]</ref>, which is an extension of word2vec. We train our own embeddings using the respective data sets and generate doc2vec vectors (paragraph vectors) as implicit knowledge representations for the candidate papers and the citation contexts. We can then use the cosine similarity for finding the nearest doc2vec paper embedding for a given doc2vec citation context embedding.</p><p>3.1.4 Paper2Vec. Paper2Vec <ref type=\"bibr\" target=\"#b12\">[13]</ref> is another embedding approach to produce document vectors (paragraph vectors) enriched by random walks. Embeddings are trained by combining the papers\\' textual information and citation information in two distinct steps. The underlying idea is that papers with semantically similar contents are placed closely together. This is then used to obtain a ranking of similar papers for recommendation. Note that Paper2Vec is used in the evaluation as a baseline but is not further described in this section, since the approach is described sufficiently in <ref type=\"bibr\" target=\"#b12\">[13]</ref>.</p><p>3.1.5 HyperDoc2Vec. The Hyperdoc2Vec approach <ref type=\"bibr\" target=\"#b13\">[14]</ref> is a general recommendation approach for hyper-documents. It can thus be applied to citation recommendation. The algorithm produces two vectors for each paper: an IN vector and an OUT vector. The idea of using dual word embeddings originates from Nalisnick et al. <ref type=\"bibr\" target=\"#b32\">[33]</ref>, who claimed that two vectors work better than one for a variety of tasks. Specifically, for a paper P, the IN document vector (d I ) represents P playing the role of a source (citing) document.</p><p>The OUT document vector (d O ) represents P playing the role of a target (cited) document. Essentially, this means that the algorithm is both content-aware and context-aware. Both the content of P (which is, in our case, either the paper\\'s full text or, if the full text is not available, a pseudo full text consisting of a title, abstract, and citation contexts where it cites other papers) and the contexts of the papers which cite P play a role in its embeddings. The trained paper embeddings can then be compared via a similarity function (e.g., cosine similarity) to find the most suitable papers for a given citation context.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.2\">Semi-Genetic Hybrid Recommender for Citation Recommendation</head><p>In this subsection, we describe an approach which uses the concept of random draws with replacement to probabilistically integrate results from different algorithms.</p><p>Recommendations from different recommender systems can be combined in several ways. One possibility is to use a stochastic weighted hybrid algorithm as described by Mueller <ref type=\"bibr\" target=\"#b31\">[32]</ref>. The algorithm is called \"semi-genetic\" because the cross-over and mutation steps of genetic algorithms are skipped. In addition, the semi-genetic algorithm has only one iteration, unlike most genetic algorithms. In the following, we adapt this hybrid algorithm for citation recommendation due to its added layer of stochasticity compared to a simple weighted approach.</p><p>Hybrid The structure of our hybrid algorithm is illustrated in Figure <ref type=\"figure\">1</ref> using 1 data set and 2 recommender systems as components. Thus, we call it Hybrid12, or simply Hybrid. Note that the algorithm works for any number of single recommendation approaches (m in the following) and data sets. The workflow is as follows:</p><p>(1) Initialize population: select a set of items from all possible \"chromosomes,\" i.e. from the recommendation lists of both component algorithms. In this step, we obtain the top k recommendations (e.g., k = 500) from each algorithm and concatenate them. (2) Evaluate fitness scores: the reciprocal rank is assigned as the fitness score for the recommendations from each of the algorithms. If a paper has been recommended by both algorithms, it will carry two associated scores. (3) Convert the scores into probabilities: this is done by dividing each score by the sum of all the scores. In case of multiple scores, the scores are first summed up. (4) Selection: we randomly draw n (e.g., n = 1 million) samples with replacement from the array of l (l = mk; e.g., l = 1000) recommendations, based on the probabilities calculated in step 3. ( <ref type=\"formula\">5</ref>) Count the number of times each of the papers is drawn. ( <ref type=\"formula\">6</ref>) Sort the recommendations in descending order of frequencies. ( <ref type=\"formula\">7</ref>) Solution set: return the top k recommendation from the sorted array of recommendations.</p><p>Hybrid23 Because the papers\\' full texts are often not available, we introduced so-called pseudo full texts of the papers, composed of the papers\\' titles, abstracts, and citation contexts which are often available (see Section 4.1). However, one can imagine that the citation contexts describe aspects of the cited papers they link to rather than the papers in which they appear (called citing papers here). For instance, in Figure <ref type=\"figure\" target=\"#fig_1\">3</ref>, the citation contexts in papers a, b, and c describe paper i better than the citation contexts in paper i itself. This assumption is also stated by Huang et al. <ref type=\"bibr\" target=\"#b17\">[18,</ref><ref type=\"bibr\" target=\"#b18\">19]</ref>. Thus, we now consider the scenario in which -besides the title and the abstract -the citation contexts of the citing papers (which link to the to-be-modeled-paper) are used (i.e., citation contexts of papers a, b, and c in Figure <ref type=\"figure\" target=\"#fig_1\">3</ref>). For Hybrid, preliminary results indicated that the combination of BM25 and the Hyperdoc2vec with OUT document vectors (hd2vOUT) as components of the hybrid recommender system leads to the best results (see <ref type=\"bibr\">Section 4)</ref>. We also choose these approaches for the specific set-up in which the citation contexts of the citing paper and cited papers are available. It makes sense to apply hd2vOUT directly on the papers to be modelled (cited papers) but not on the citing papers. Thus, we end up with the following three recommender systems as components of our advanced hybrid approach:</p><p>(1) hd2vOUT trained on a pseudo full text data set containing titles, abstracts, and citation contexts from the cited papers;</p><p>(2) BM25 trained on a pseudo full text data set containing titles, abstracts, and citation contexts from the cited papers;</p><p>(3) BM25 trained on a pseudo full text data set containing titles, abstracts, and citation contexts from the citing papers. Since this adapted hybrid citation recommendation system is based on two data sets (containing citation contexts from citing papers and citation contexts from the to-be-modeled (i.e., cited) papers) and contains three components, we call it Hybrid23 in the remaining paper.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4\">EVALUATION</head><p>Citation recommender systems are arguably more difficult to evaluate than other types of recommender systems due to the contextawareness and high number of candidate papers (e.g., 1+M). The evaluation depends heavily on the ground truths which are chosen. In the case of an offline evaluation, the ground truths are the papers cited by the original authors in the test citation contexts. Thus, the task is to re-predict the citations. However, this kind of evaluation is arguably subjective. There is no reason to believe that all the test contexts\\' authors have cited the correct papers. For this reason, we conduct an online evaluation (user study) in conjunction with an offline evaluation (see Section 4.4).</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.1\">Evaluation Data Sets</head><p>The amount and quality of real-world data used for training a machine learning model is arguably more important than the quality of the actual algorithms used. Thus, the preparation of the input data is a critical step in the whole process. In the following subsections, we describe our data sources, our data preparation steps, as well as our final data sets used. The entire process is depicted in Figure <ref type=\"figure\" target=\"#fig_0\">2.</ref> 4.1.1 Data Source. The following three data sources are used in this paper. 3  Microsoft Academic Graph (MAG) The MAG <ref type=\"bibr\" target=\"#b36\">[37]</ref>, a relatively new data set, contains metadata (title, abstract, sometimes citation contexts, etc.) from 220 million papers (as of 22 May 2019). Note that the MAG provides no full texts. Papers in the data set range all the way from the years 1800 to 2019.</p><formula xml:id=\"formula_0\">MAG arXiv ACL-ARC ----- ------------- -------- ------------- ------------- ---- -------------</formula></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Meta data only Fulltext Fulltext</head><p>Create pseudo fulltext by concatenating meta data</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>MAG</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Data Sources</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Data Preparation</head><p>Map arXiv to MAG Map ACL to MAG arXiv ACL</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>MAG MAG</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Meta data as pseudo fulltext</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Data Sets arXiv-MAG</head><p>Fulltext &amp; pseudo fulltext for papers without fulltext</p><formula xml:id=\"formula_1\">&#8226; ----- &#8226; -------- &#8226; ---------- &#8226; -------- &#8226; ---------- &#8226; ------ ACL- MAG MAG MAG50 MAG- Cited ----- ------------- -------- ------------- ------------- ---- ------------- ----- ------------- -------- ------------- ------------- ---- ------------- Fulltext Fulltext ----- ------------- ------------ ------------- ----- ----------- ----- ------------- -------- ------------- ------------- ---- ------------- ----- ------------- -------- ------------- ------------- ---- ------------- ----- ------------- ------------ ------------- ----- ----------- ----- ------------- -------- ------------- ------------- ---- ------------- ----- ------------- ------------ ------------- ----- ----------- ----- ------------- ------------ ------------- ----- ----------- ----- ------------- ------------ ------------- ----- ----------- ----- ------------- ------------ ------------- ----- -----------</formula></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Meta data as pseudo fulltext</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Meta data as pseudo fulltext</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Meta data as pseudo fulltext</head><p>Papers  arXiv Although arXiv 4 does not quite match the breadth of coverage in the MAG, it still contains a substantial number of papers (overall over 1.5 million submissions as of 22 May 2019). The papers are from mainly five disciplines -mathematics, computer science, physics, biology, and economics. While citation contexts are not directly available, the full text in PDF as well as L A T E X files can be obtained for almost all arXiv papers. We use the plain texts extracted from T E X source files as provided by Saier and F&#228;rber <ref type=\"bibr\" target=\"#b35\">[36]</ref>. In this way, we obtain full and clean text data of all arXiv papers.</p><p>ACL Anthology (ACL-ARC) The ACL Anthology Reference corpus is a comparatively tiny data set which covers only computational linguistics and natural language processing. It contains close to 11,000 papers and stretches from 1965 to 2006. The ACL data we use for this paper has been provided in a preprocessed format by F&#228;rber et al. <ref type=\"bibr\" target=\"#b10\">[11]</ref>, containing sentences, reference information, and publications\\' metadata.</p><p>4.1.2 Data Set Preparation. The first step was to restrict the data sets to only include papers from the field of computer science. Advantages to using only one discipline include likely better recommendations and reduced training time for embedding-based algorithms while missing out on cross-domain recommendations.</p><p>The MAG data set does not contain full text but rather citation contexts and plenty of metadata in a good quality which needs to be prepared for our content-based algorithms. Therefore, a mechanism is needed to combine the contexts and metadata into a form usable by our algorithms. Thus, we retrieved and concatenated the title, abstract, and citation contexts for each paper to form text which acts as a substitute and which we call the pseudo full text.</p><p>In case of the non-MAG data sets, the papers\\' full text was available. Nevertheless, we mapped the papers to the MAG to enrich their metadata with additional citation information as far as it was missing. Title, abstract, and the citation contexts are retrieved and concatenated to form pseudo full text. The reason we go through  this process is that one of the used embedding algorithms (Hyper-doc2vec) requires representations for every citing and cited paper, but we cannot ensure that the full texts of all cited and citing documents will be available because they might not be covered by arXiv/ACL-ARC.</p><p>4.1.3 Data Sets. Table <ref type=\"table\" target=\"#tab_2\">1</ref> gives an overview of the train/test splits of the used evaluation data sets. MAG To prepare the MAG training set, the dump files are loaded into several PostgreSQL tables. From there, the pseudo full text is prepared for each paper. The test set uses citation contexts from computer science papers in English which were published in 2018 and 2019.</p><p>MAG-50 Here, the data preparation is very similar to the regular MAG data set, the difference being that only papers which have been cited at least 50 times are included in the training set. This means that papers with fewer citations, such as newly published papers, will not get recommended. This data set is used for comparison and analysis purposes.</p><p>MAG with cited contexts (MAG-Cited) Huang et al. <ref type=\"bibr\" target=\"#b17\">[18,</ref><ref type=\"bibr\" target=\"#b18\">19]</ref> claimed that \"a citation\\'s context contains explicit words explaining the citation. \" In other words, the words in a citation context explain the cited paper rather than the actual (i.e., citing) paper. We try to verify this claim by creating an alternative data set where each pseudo full text consists of citation contexts taken from papers which cite it, i.e., where it acts as the target of a citation rather than the source (see in Figure <ref type=\"figure\" target=\"#fig_1\">3</ref> the citation contexts in the papers a, b, and c for modeling paper i).</p><p>arXiv-MAG In contrast to MAG, arXiv and ACL contain the full text of papers. Our evaluation on these data sets aims to determine the effect full text has on citation recommendation.</p><p>For arXiv-MAG, we reuse the approach by Saier and F&#228;rber <ref type=\"bibr\" target=\"#b35\">[36]</ref> to convert L A T E Xsource files provided by arXiv into text files and create a database in which the papers in the reference section of each paper are mapped to MAG. A couple of filter conditions are applied on the data set of arXiv papers: only computer science papers from 1991 to 2017 are considered (until 2016 for training) and papers which have been cited less than five times are discarded. Furthermore, as our final data set will contain additional data from MAG (pseudo full text), it is necessary to map all the arXiv IDs to MAG IDs. All the arXiv papers which cannot be mapped to the MAG are therefore discarded in the training set.</p><p>Pseudo full text is fetched from the MAG for the cited papers which are not within the reduced arXiv data set.</p><p>To prepare the test set, the citation contexts of computer science papers from 2017 are extracted from arXiv. Like in the training set, the arXiv IDs of the cited papers are mapped to MAG IDs, and act as the ground truth. Again, references which are not in the training set are discarded from the ground truth.</p><p>ACL-MAG F&#228;rber et al. <ref type=\"bibr\" target=\"#b10\">[11,</ref><ref type=\"bibr\" target=\"#b11\">12]</ref> described a method to detect citation contexts from ACL Anthology (and arXiv) papers and provide the corresponding data online. They obtained the references of each paper and mapped them to the bibliography database DBLP. The data was divided into 3 files for each paper: a text file containing the full text and annotations for citation markers, a references file, and a metadata file.</p><p>To create the training set, we make use of the text files and only consider citation annotations with links to DBLP. DBLP papers are mapped to the MAG in the same way as in the case of arXiv. The in-text annotations with DBLP IDs are then replaced by annotations with MAG IDs. The training data contains all papers from 1965 to 2005. Again, additional MAG pseudo-text is added for these papers\\' reference papers.</p><p>The test set contains citation contexts from ACL Anthology papers in 2006. The papers in the ground truth are fetched from the references and mapped to the MAG in the same way as the training set. Any papers not in the training set are removed from the ground truth. Unlike arXiv, all the test set contexts have only one paper in the ground truth.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.1.4\">Analysis on</head><p>Training and Test Sets. The number of training set papers has interesting ramifications for the evaluation results. In general, it is reasonable to expect that complex algorithms perform better with more training examples. As a result, we hypothesize that less complex algorithms might perform better with fewer training examples. To examine that, the number of training examples varies widely across data sets, with ACL-MAG at the lower end and the regular MAG data set at the higher end.</p><p>Apart from the algorithms themselves, the number of citation contexts in the test sets also have a big effect on the evaluation results. The higher the number of test set contexts, the higher the confidence we can have in the results. The training-test split is done based on years for all the data sets, as shown in Table <ref type=\"table\" target=\"#tab_2\">1</ref>. The number of test set contexts from these papers varies widely, too, with ACL-MAG being by far the smallest data set in these terms and arXiv-MAG the largest (the ratio of test set contexts to training set papers for arXiv-MAG is also the highest).</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.2\">Evaluation Metrics</head><p>We follow related works and use the following evaluation metrics:</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Mean Average Precision (MAP):</head><p>The mean average precision is the mean of the average precision values over multiple queries (test set contexts). Let the average precision of the recommendations for all the n test set contexts be AP 1 , AP 2 , AP3, ..., AP n . Then,</p><formula xml:id=\"formula_2\">MAP = n i=1 AP i n</formula><p>Recall@k: Recall is a measure which gives the percentage of true positives found in the first k recommendations for a single query. In other words, Recall@k gives the average recall over all n test set contexts:</p><formula xml:id=\"formula_3\">Recall = n i=1 R i n</formula><p>where R i is the recall for a single test set context.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Mean Reciprocal Rank (MRR):</head><p>The reciprocal rank is the reciprocal of the rank of a relevant item. The MRR is obtained by averaging the reciprocal ranks over all queries. It is a metric which is most often used when there is only one relevant item. As the test sets in this paper generally have only one relevant item in the ground truth list, this is a useful metric.</p><p>Normalized Discounted Cumulative Gain (NDCG): The discounted cumulative gain assumes that relevant documents have different degrees of relevance. Let rel(r i ) be the relevance score. Then,</p><formula xml:id=\"formula_4\">DCG@k = rel(r 1 ) 1 + k i=2 rel(r i ) lo&#1076; 2 i</formula><p>where the denominator for i=1 is 1 (as lo&#1076; 2 1 = 0). The ideal DCG@k (IDCG@k) is calculated by sorting the top k recommendations in descending order and calculating the DCG@k.</p><p>The normalized discounted gain for a single query is obtained by dividing the DCG@k by the ideal DCG@k:</p><p>N DCG@k = DCG@k IDCG@k This is divided by the number of queries to get the final mean NDCG@k.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.3\">Offline Evaluation</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.3.1\">Evaluation</head><p>Setting. We use the following approaches in our offline evaluation:</p><p>&#8226; Information retrieval methods: BM25.</p><p>&#8226; Topic modelling methods: Variational Bayes LDA used as a baseline (LDA Mallet is included for ACL-MAG) with number of topics as 300 for all the large data sets and 200 for the small ACL-MAG data set. &#8226; Embedding-based methods: Paper2Vec, Doc2Vec, hd2vOUT</p><p>(with only OUT document vectors), hd2vINOUT (with IN and OUT document vectors). &#8226; Semi-genetic hybrid algorithms: Hybrid based on BM25 and hd2vOUT, Hybrid23 based on BM25 and hd2vOUT and using both citing and cited papers (see Section 3.2). Exploratory experiments conducted across data sets indicate a huge variance in performance between approaches. Using all the algorithms as part of the hybrid recommender did not seem to  increase recall. Therefore, Hybrid and Hybrid23 combine recommendations from only the BM25 recommender and the Hyperdoc2vec recommender using OUT document vectors (hd2vOUT).</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.3.2\">Evaluation Results with MAG.</head><p>Figure <ref type=\"figure\" target=\"#fig_2\">4</ref> shows the evaluation results for all the models tested using the MAG data set without any restriction on the number of citations. It is clear from the graph that the hybrid model showcases the best results with respect to all used metrics. This is not a surprise as it combines the best parts of the next two best models, BM25 and hd2vOUT. While hd2vOUT has marginally higher recall at k = 10, BM25 has slightly higher MRR and MAP. Unlike on the other data sets, hd2vINOUT performs very badly. This indicates that using the contexts and the abstract as pseudo full text is not enough to generate high quality IN embeddings. The much higher hd2vOUT values show that the OUT embeddings are of much better quality. The OUT embeddings correspond to the papers playing the role of a cited document. Hence, this shows that Hyperdoc2vec is highly context-aware.</p><p>The performance of LDA is below average, but it does better than hd2vINOUT for the MAG data set. Paper2Vec and Doc2Vec perform abysmally across metrics.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.3.3\">Evaluation Results with MAG50.</head><p>One would expect MAG50 to produce better results for all the algorithms on all the metrics, due to the overall smaller candidate pool for each paper. This is indeed the case at k = 10 (see Table <ref type=\"table\" target=\"#tab_3\">2</ref>). All the metric values are significantly higher than on all other data sets. This is because the data sets are of similar quality, but the number of candidates for each recommendation is much smaller for MAG50 than for MAG. Consequently, it is more likely that the relevant items are near the top of the list of recommendations.</p><p>However, it cannot be concluded that a system using MAG50 always produces better results. Less popular papers and very new papers are not recommended while using the MAG50 data set even though they may be perfectly valid recommendations. Thus, Hy-brid23, our advanced hybrid recommender system, is based on both the MAG and MAG50.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.3.4\">Evaluation</head><p>Results with arXiv-MAG. We observe some interesting patterns in the evaluation results for arXiv-MAG from Figure <ref type=\"figure\" target=\"#fig_3\">5</ref>. Unlike when using MAG, hd2vOUT performs better than BM25 across metrics. hd2vINOUT performs almost as well as BM25. This proves an important point, namely that Hyperdoc2Vec produces better IN embeddings (IN document vectors) when the full content is available for a large number of papers. The presence of accurate positions of citation markers in the content from arXiv may have played a role in pushing the performance of hd2vOUT over the text-based BM25 algorithm. This is due to the better quality of OUT document vectors. While arXiv-MAG also contains papers with only pseudo full text, it clearly does better with IN embeddings due to the presence of many full text papers from arXiv.</p><p>LDA, again, obtains mediocre results on the metrics. Paper2Vec\\'s and Doc2Vec\\'s performance again show why they were not worth being used in the hybrid algorithm.</p><p>Comparing the values of the metrics for arXiv-MAG and the MAG at k = 10, we see that MAP and MRR for hd2vOUT are higher for arXiv-MAG than for the MAG across algorithms. One important consideration to take into account is that arXiv-MAG has a higher percentage of test contexts with more than 1/2/3 papers in the ground truth. This improves the probability of getting some of them in the top 10 results, and therefore improves the MAP and the MRR.</p><p>There is not much difference between the performance of BM25 on the MAG and arXiv-MAG data sets in regard to MAP and MRR. This is interesting as it indicates that BM25 performs better on MAG. This could be because a text-based algorithm like BM25 might perform better when the text content is homogeneous across papers. The MAG has pseudo-full text for all papers, while arXiv has full text for some papers and pseudo-full text for others.</p><p>The recall is consistently higher across algorithms for MAG than arXiv-MAG. This, again, might have a lot to do with the presence of a lot of ground truths with 4 or more papers in arXiv-MAG. The recall suffers due to this (as opposed to the MAP) as a higher percentage of papers in the ground truth are missing in the top 10 results.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.3.5\">Evaluation Results with ACL-MAG.</head><p>Moving on to ACL-MAG, which has a very low number of test set contexts, we notice a few common patterns in Figure <ref type=\"figure\" target=\"#fig_4\">6</ref>. Method hd2vOUT outperforms BM25 in every metric, which is closely followed by hd2vINOUT. This reinforces the point made that the IN document embeddings are better when some papers have full text. The higher MAP and MRR when compared with the MAG may simply be due to the sheer difference in size of the test sets.  At the end of the offline recommendation phase, we see a clear hierarchy in the performance of the algorithms across data sets and evaluation metrics. The hybrid algorithm performs the best and the two components of the hybrid algorithm, hd2vOUT and BM25 are the second and third best. This is followed by hd2vINOUT and LDA. The other embedding algorithms, Paper2Vec and Doc2Vec, perform very poorly.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>4.3.6</head><p>Case Study Using BM25 on 2 MAG Data Sets. In this subsection, we perform a brief case study to test the assertion made in Huang et al.\\'s two papers <ref type=\"bibr\" target=\"#b17\">[18,</ref><ref type=\"bibr\" target=\"#b18\">19]</ref> that citation contexts describe the cited paper rather than the citing paper. This is done using the BM25 algorithm and the data sets MAG and MAG-Cited.</p><p>For the MAG, the pseudo full text for a paper consists of its title, abstract, and citation contexts. In contrast, in case of MAG-Cited, a paper\\'s pseudo full text is made up of its title, abstract, and citation contexts from papers which cite it. In other words, the content of a cited paper contains citation contexts from all its citing papers.</p><p>Running the BM25 algorithm on both data sets, we find that there is a significant difference in the evaluation results (see Figure <ref type=\"figure\" target=\"#fig_6\">7</ref>). The evaluation results show that using the citation contexts of a citing paper as the content of a cited paper pays off. Our evaluation    results support Huang et al. \\'s assertion. We incorporate this finding when designing the improved hybrid system Hybrid23. The graphs in Figure <ref type=\"figure\" target=\"#fig_8\">8</ref> compare the original hybrid algorithm with Hybrid23 and BM25 trained on MAG-Cited. Comparing Hy-brid23 and BM25 (MAG-Cited), we see that the recall, MAP, and MRR start to get higher for Hybrid23 as k becomes larger. The recall curves, especially, start to diverge around k = 5. Both algorithms are well ahead of the original hybrid algorithm on all the metrics.</p><p>A quick look at k = 10 makes it clear that Hybrid23 and BM25 (MAG-Cited) have MAP and MRR values twice as high as the Hybrid algorithm, with substantially higher recall. It is also interesting to note the differences between BM25 (MAG-Cited) and Hybrid23. While there is not too much difference between their MAP and MRR values at k = 10, a 2.5% gain in recall is very significant. In fact, the recall@10 is more than 0.5 for Hybrid23, which indicates that a paper from the ground truth is found in the top 10 recommendations in half the test cases.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4.4\">Online Evaluation</head><p>We performed a user study in which users (researchers familiar in their research fields) manually rate the recommendations for a number of citation contexts based on the recommendation approaches BM25, hd2vOUT, and Hybrid as well as MAG as data set (with no restriction as to the number of citations). We chose these approaches since they performed best in the offline evaluation on the MAG data set. We did not include Hybrid23 in this user study, since we have restricted the user study to the best algorithms which work on a single data set.</p><p>Data Set Creation. Citation contexts are extracted from the MAG based on language and field of study. English citation contexts are chosen from the natural language processing field as it closely relates to the topic of the paper and the participants\\' research fields. All the citation contexts are chosen from 2018 and 2019. These contexts were seen in the offline evaluation test set. Contexts which cite papers not from the training set are discarded. Duplicate contexts are grouped together. Additionally, citation contexts with 8 or fewer words (stop words not included) are discarded.</p><p>Evaluation Process. From the 8,356 surviving citation contexts, random sampling is performed to pick 100 citation contexts for the user study. 10 recommendations are made for each of these 100 citation contexts using each of the three chosen algorithms. An example can be seen in Table <ref type=\"table\">3</ref>. The corresponding metadatatitle, abstract, and the published year-are retrieved from the MAG database.</p><p>The number of relevant papers for a test citation context is unavailable, unlike in the offline evaluation process. Instead, an approximation is made. The number of relevant results is approximated to be the sum of the results returned by hd2vOUT and BM25. The reason for this approximation is that in a vast majority of cases, the valid results picked by the user for the hybrid algorithm were from the top 10 results of hd2vOUT and BM25. The two individual models often complement each other and pick different results. In many cases, hd2vOUT was found to recommend more general results (e.g. survey papers and often-cited papers), while BM25 was found to recommend more specific results. This approximation only affects the calculation of recall.</p><p>We report three metrics for the online evaluation: MAP, MRR, and recall. We do not report NDCG values because the recommendations are binary and not graded.</p><p>Evaluation results. The evaluation results are shown in Table <ref type=\"table\" target=\"#tab_4\">4</ref>. The proposed hybrid model outperforms the other models by a large margin. They indicate that BM25 plays a dominant role in the hybrid algorithm and outperforms hd2vOUT. However, there are a number of caveats with the online evaluation. The number of test set contexts is very small. The selection of relevant papers by the user is subjective, and the citation contexts are sometimes ambiguous. The recommendations were selected only from one small field of study of computer science -natural language processing.</p><p>The user study allows us to make a number of inferences. hd2vOUT sometimes recommended general papers relating to the concepts or claims mentioned in the citation contexts. BM25, being a text-based algorithm, recommended more specific results. As a result, their combination in the hybrid algorithm tends to combine the best of both worlds.</p><p>Table <ref type=\"table\">3</ref>: Example of citation recommendation from the online evaluation. The table shows recommendations from our hybrid recommender as well as its component algorithms. Note: blue = ground truth; red = other possibly valid predictions; unhighlighted = invalid or general recommendations related to the context. It becomes apparent that the actual ground truth papers are included at different ranks in the hybrid and the component algorithms. Other similar papers are recommended as well.</p><p>Citation context: \"CCG is still able to use a very compact representation of the lexicon, and at the same time to handle non-local dependencies in a simple and effective way. After the release of CCG-annotated datasets [X], there has also been a surge of interest in this formalism within statistical natural language processing, and a wide range of applications including data-driven parsing  Another observation was that oftentimes, recommendations which are not perfectly suitable for the citation context might still be interesting to the end user. There are some papers which touch on the topic of the citation context, or survey papers about a related research topic that might still be useful for the end user. This serendipity is a hallmark of recommender systems in general, and it could help researchers discover new topics related to their research areas. Our hybrid recommender performs very well in this regard, which is not reflected in pure metrics-based analysis alone.</p><p>The user study also shows that there are a number of citation contexts for which no recommendations are possible. Finally, it confirms the belief from the offline evaluation that BM25 and such textbased information retrieval algorithms work as well as or better on the citation recommendations task than more complex algorithms.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"5\">CONCLUSION</head><p>In this paper, we adapted and applied several algorithms for local citation recommendation (Paper2Vec, HyperDoc2Vec, LDA, and BM25). Furthermore, we combined approaches into the first fully hybrid recommendation approach for local citation recommendation. For the evaluation, multiple data sets were created and made publicly available. In the evaluation, we demonstrated the superiority of our hybrid approach over the others based on recall, MRR, MAP, and NDCG metrics. Based on our findings, we have further improved our hybrid algorithm by incorporating the citing papers\\' contexts, thereby creating our Hybrid23 algorithm.</p><p>For the future, we plan to explore the creation of a machine learning algorithm which can discard more incomplete citation contexts from the pseudo full text and thus improve the quality of the training data.</p></div><figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_0\"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Data set creation process.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_1\"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: In case of MAG, the pseudo full text of paper i consists of its citation contexts for paper x, y, and z. In case of MAG-Cited, the pseudo full text of paper i consists of citation contexts from papers a, b, and c where paper i is cited.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_2\"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Evaluation using MAG.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_3\"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Evaluation using arXiv-MAG.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_4\"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Evaluation using ACL-MAG.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_6\"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Comparing BM25 performance for the data sets MAG and MAG-Cited.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_8\"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Comparing Hybrid23 with BM25 (MAG-Cited) and the original Hybrid algorithm.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_9\"><head/><label/><figDesc>[Y]. \" Original citations [X]: \"CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank,\" [Y]: \"Wide-Coverage Efficient Statistical Parsing with CCG and Log-Linear Models. \" Data-Driven Parser-Generator for Dependency Parsing Chinese CCGbank: extracting CCG derivations from the Penn Chinese Treebank Wide-coverage efficient statistical parsing with ccg and log-linear models 2 Wide-coverage efficient statistical parsing with ccg and log-linear models Rebanking CCGbank for Improved NP Interpretation Accurate Unlexicalized Parsing 3 Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms Shift-Reduce CCG Parsing Shift-Reduce CCG Parsing 4 The importance of supertagging for widecoverage CCG parsing A New Parsing Algorithm for Combinatory Categorial Grammar Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data 5 Accurate Unlexicalized Parsing Creating a CCGbank and a Wide-Coverage CCG Lexicon for German The Proposition Bank: An Annotated Corpus of Semantic Roles 6 Online Large-Margin Training of Dependency Parsers Semi-supervised lexical acquisition for widecoverage parsing CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank 7 Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data A Data-Driven, Factorization Parser for CCG Dependency Structures Semi-supervised lexical acquisition for widecoverage parsing 8 The Proposition Bank: An Annotated Corpus of Semantic Roles A* CCG Parsing with a Supertag-factored Model A Data-Driven, Factorization Parser for CCG Dependency Structures 9 Natural Language Processing (Almost) from Scratch Using CCG categories to improve Hindi dependency parsing Using CCG categories to improve Hindi dependency parsing 10 CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank An Incremental Algorithm for Transition-based CCG Parsing An Incremental Algorithm for Transition-based CCG Parsing</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_2\"><head>Table 1 :</head><label>1</label><figDesc>Details about training and test sets.</figDesc><table><row><cell>Data Set</cell><cell>Training</cell><cell cols=\"2\">Test Years #Training</cell><cell>#Test</cell></row><row><cell/><cell>Years</cell><cell/><cell>Papers</cell><cell>Contexts</cell></row><row><cell>ACL-MAG</cell><cell>1965-2005</cell><cell>2006</cell><cell>11,217</cell><cell>2,775</cell></row><row><cell>arXiv-MAG</cell><cell>1991-2016</cell><cell>2017</cell><cell>376,218</cell><cell>286,272</cell></row><row><cell>MAG</cell><cell>1800-2017</cell><cell>2018-2019</cell><cell>1,620,841</cell><cell>168,700</cell></row><row><cell>MAG50</cell><cell>1800-2017</cell><cell>2018-2019</cell><cell>126,666</cell><cell>107,781</cell></row><row><cell>MAG-Cited</cell><cell>1800-2017</cell><cell>2018-2019</cell><cell>1,478,924</cell><cell>190,991</cell></row></table></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_3\"><head>Table 2 :</head><label>2</label><figDesc>Evaluation scores at k = 10 for all models using the MAG50 data.</figDesc><table><row><cell>Model</cell><cell cols=\"4\">MRR@10 Recall@10 MAP@10 NDCG@10</cell></row><row><cell>BM25</cell><cell>0.1528</cell><cell>0.2836</cell><cell>0.1528</cell><cell>0.2082</cell></row><row><cell>LDA</cell><cell>0.0369</cell><cell>0.0892</cell><cell>0.0369</cell><cell>0.0567</cell></row><row><cell>Doc2Vec</cell><cell>0.0000008</cell><cell cols=\"2\">0.000005 0.0000008</cell><cell>0.000006</cell></row><row><cell>Paper2Vec</cell><cell>0.0025</cell><cell>0.0113</cell><cell>0.0026</cell><cell>0.0055</cell></row><row><cell>hd2vOUT</cell><cell>0.1233</cell><cell>0.2200</cell><cell>0.1233</cell><cell>0.1660</cell></row><row><cell>hd2vINOUT</cell><cell>0.0595</cell><cell>0.1353</cell><cell>0.1873</cell><cell>0.0898</cell></row><row><cell>Hybrid</cell><cell>0.1873</cell><cell>0.3760</cell><cell>0.1873</cell><cell>0.2711</cell></row></table></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_4\"><head>Table 4 :</head><label>4</label><figDesc>Online evaluation at k = 10 using the MAG data set.</figDesc><table><row><cell>Model</cell><cell cols=\"3\">MAP@10 Recall@10 MRR@10</cell></row><row><cell>BM25</cell><cell>0.362</cell><cell>0.541</cell><cell>0.380</cell></row><row><cell>hd2vOUT</cell><cell>0.314</cell><cell>0.385</cell><cell>0.315</cell></row><row><cell>Hybrid</cell><cell>0.370</cell><cell>0.680</cell><cell>0.411</cell></row></table></figure>\\n\\t\\t\\t<note xmlns=\"http://www.tei-c.org/ns/1.0\" place=\"foot\" n=\"1\">The source code is available online at https://github.com/ashwath92/HybridCite.<ref type=\"bibr\" target=\"#b1\">2</ref> See https://github.com/ashwath92/HybridCite.</note>\\n\\t\\t\\t<note xmlns=\"http://www.tei-c.org/ns/1.0\" place=\"foot\" n=\"3\">Note that other data sets containing papers\\' metadata and citation contexts exist (e.g., RefSeer<ref type=\"bibr\" target=\"#b19\">[20]</ref>). However, we found the quantity and quality of the papers\\' metadata and citation contexts in MAG to be much higher. Furthermore, in case of RefSeer, not much data is available for the cited papers which makes it unfit for our approaches.</note>\\n\\t\\t\\t<note xmlns=\"http://www.tei-c.org/ns/1.0\" place=\"foot\" n=\"4\">https://arxiv.org/</note>\\n\\t\\t</body>\\n\\t\\t<back>\\n\\t\\t\\t<div type=\"references\">\\n\\n\\t\\t\\t\\t<listBibl>\\n\\n<biblStruct xml:id=\"b0\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Content-Based Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Chandra</forename><surname>Bhagavatula</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Sergey</forename><surname>Feldman</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Russell</forename><surname>Power</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Waleed</forename><surname>Ammar</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT\\'18</title>\\n\\t\\t\\t\\t<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT\\'18</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"238\" to=\"251\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b1\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">The ACL Anthology Reference Corpus: A Reference Dataset for Bibliographic Research in Computational Linguistics</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Steven</forename><surname>Bird</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Robert</forename><surname>Dale</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Bonnie</forename><forename type=\"middle\">J</forename><surname>Dorr</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Bryan</forename><forename type=\"middle\">R</forename><surname>Gibson</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Mark</forename><forename type=\"middle\">Thomas</forename><surname>Joseph</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Min-Yen</forename><surname>Kan</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Dongwon</forename><surname>Lee</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Brett</forename><surname>Powley</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">R</forename><surname>Dragomir</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yee</forename><forename type=\"middle\">Fan</forename><surname>Radev</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><surname>Tan</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the International Conference on Language Resources and Evaluation (LREC\\'08)</title>\\n\\t\\t\\t\\t<meeting>the International Conference on Language Resources and Evaluation (LREC\\'08)</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2008\">2008</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b2\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Latent Dirichlet Allocation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">David</forename><forename type=\"middle\">M</forename><surname>Blei</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Andrew</forename><forename type=\"middle\">Y</forename><surname>Ng</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Michael</forename><forename type=\"middle\">I</forename><surname>Jordan</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Journal of Machine Learning Research</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">3</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"993\" to=\"1022\"/>\\n\\t\\t\\t<date type=\"published\" when=\"2003\">2003. 2003</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b3\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Hybrid Recommender Systems: Survey and Experiments</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Robin</forename><surname>Burke</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">User Modeling and User-Adapted Interaction</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">12</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"331\" to=\"370\"/>\\n\\t\\t\\t<date type=\"published\" when=\"2002\">2002. 2002</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b4\">\\n\\t<monogr>\\n\\t\\t<title level=\"m\" type=\"main\">Hybrid Web Recommender Systems</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Robin</forename><surname>Burke</surname></persName>\\n\\t\\t</author>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2007\">2007</date>\\n\\t\\t\\t<publisher>Springer</publisher>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"377\" to=\"408\"/>\\n\\t\\t\\t<pubPlace>Berlin Heidelberg; Berlin, Heidelberg</pubPlace>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b5\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Generative Adversarial Network Based Heterogeneous Bibliographic Network Representation for Personalized Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xiaoyan</forename><surname>Cai</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Junwei</forename><surname>Han</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Libin</forename><surname>Yang</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18</title>\\n\\t\\t\\t\\t<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"5747\" to=\"5754\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b6\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Rhetorical Classification of Anchor Text for Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Daniel</forename><surname>Duma</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Ewan</forename><surname>Klein</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Maria</forename><surname>Liakata</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">James</forename><surname>Ravenscroft</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Amanda</forename><surname>Clare</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">D-Lib Magazine</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">22</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">10</biblScope>\\n\\t\\t\\t<date type=\"published\" when=\"2016\">2016. 2016</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b7\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Applying Core Scientific Concepts to Context-Based Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Daniel</forename><surname>Duma</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Maria</forename><surname>Liakata</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Amanda</forename><surname>Clare</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">James</forename><surname>Ravenscroft</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Ewan</forename><surname>Klein</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\\'16</title>\\n\\t\\t\\t\\t<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC\\'16</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2016\">2016</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"1737\" to=\"1742\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b8\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Neural Citation Network for Context-Aware Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Travis</forename><surname>Ebesu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yi</forename><surname>Fang</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR \\'17</title>\\n\\t\\t\\t\\t<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR \\'17</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2017\">2017</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"1093\" to=\"1096\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b9\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Citation Recommendation: Approaches and Datasets</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Michael</forename><surname>F&#228;rber</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Adam</forename><surname>Jatowt</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">International Journal on Digital Libraries</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2020\">2020. 2020</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b10\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">A High-Quality Gold Standard for Citation-based Tasks</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Michael</forename><surname>F&#228;rber</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Alexander</forename><surname>Thiemann</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Adam</forename><surname>Jatowt</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the International Conference on Language Resources and Evaluation (LREC\\'18</title>\\n\\t\\t\\t\\t<meeting>the International Conference on Language Resources and Evaluation (LREC\\'18</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"1885\" to=\"1889\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b11\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">To Cite, or Not to Cite? Detecting Citation Contexts in Text</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Michael</forename><surname>F&#228;rber</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Alexander</forename><surname>Thiemann</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Adam</forename><surname>Jatowt</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 40th European Conference on Information Retrieval (ECIR\\'18</title>\\n\\t\\t\\t\\t<meeting>the 40th European Conference on Information Retrieval (ECIR\\'18</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"598\" to=\"603\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b12\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Paper2vec: Combining Graph and Text Information for Scientific Paper Representation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Soumyajit</forename><surname>Ganguly</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Vikram</forename><surname>Pudi</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 39th European Conference on Information Retrieval (ECIR\\'17</title>\\n\\t\\t\\t\\t<meeting>the 39th European Conference on Information Retrieval (ECIR\\'17</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2017\">2017</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"383\" to=\"395\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b13\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">hyperdoc2vec: Distributed Representations of Hypertext Documents</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Jialong</forename><surname>Han</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yan</forename><surname>Song</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Wayne Xin Shuming</forename><surname>Shi</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Haisong</forename><surname>Zhang</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL\\'18</title>\\n\\t\\t\\t\\t<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (ACL\\'18</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"2384\" to=\"2394\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b14\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Citation Recommendation Without Author Supervision</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Qi</forename><surname>He</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Daniel</forename><surname>Kifer</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Jian</forename><surname>Pei</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Prasenjit</forename><surname>Mitra</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">C. Lee</forename><surname>Giles</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the Fourth ACM International Conference on Web Search and Data Mining (WSDM \\'11)</title>\\n\\t\\t\\t\\t<meeting>the Fourth ACM International Conference on Web Search and Data Mining (WSDM \\'11)<address><addrLine>New York, NY, USA</addrLine></address></meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<publisher>ACM</publisher>\\n\\t\\t\\t<date type=\"published\" when=\"2011\">2011</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"755\" to=\"764\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b15\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Context-aware Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Qi</forename><surname>He</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Jian</forename><surname>Pei</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Daniel</forename><surname>Kifer</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Prasenjit</forename><surname>Mitra</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Lee</forename><surname>Giles</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 19th International Conference on World Wide Web (WWW \\'10</title>\\n\\t\\t\\t\\t<meeting>the 19th International Conference on World Wide Web (WWW \\'10</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2010\">2010</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"421\" to=\"430\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b16\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">A Model of Relevant Common Author and Citation Authority Propagation for Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Bo-Yu</forename><surname>Hsiao</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Chih-Heng</forename><surname>Chung</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Bi-Ru</forename><surname>Dai</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 16th IEEE International Conference on Mobile Data Management (MDM\\'15</title>\\n\\t\\t\\t\\t<meeting>the 16th IEEE International Conference on Mobile Data Management (MDM\\'15</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2015\">2015</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"117\" to=\"119\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b17\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Recommending Citations: Translating Papers into References</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Wenyi</forename><surname>Huang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Saurabh</forename><surname>Kataria</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Cornelia</forename><surname>Caragea</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Prasenjit</forename><surname>Mitra</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">C</forename><forename type=\"middle\">Lee</forename><surname>Giles</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Lior</forename><surname>Rokach</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 21st ACM International Conference on Information and Knowledge Management (CIKM\\'12</title>\\n\\t\\t\\t\\t<meeting>the 21st ACM International Conference on Information and Knowledge Management (CIKM\\'12</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2012\">2012</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"1910\" to=\"1914\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b18\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">A Neural Probabilistic Model for Context Based Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Wenyi</forename><surname>Huang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Zhaohui</forename><surname>Wu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Chen</forename><surname>Liang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Prasenjit</forename><surname>Mitra</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">C. Lee</forename><surname>Giles</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI\\'15)</title>\\n\\t\\t\\t\\t<meeting>the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI\\'15)</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<publisher>AAAI Press</publisher>\\n\\t\\t\\t<date type=\"published\" when=\"2015\">2015</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"2404\" to=\"2410\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b19\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">RefSeer: A citation recommendation system</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Wenyi</forename><surname>Huang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Zhaohui</forename><surname>Wu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Prasenjit</forename><surname>Mitra</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">C. Lee</forename><surname>Giles</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 14th Joint Conference on Digital Libraries (JCDL\\'14</title>\\n\\t\\t\\t\\t<meeting>the 14th Joint Conference on Digital Libraries (JCDL\\'14</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2014\">2014</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"371\" to=\"374\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b20\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Citation Recommendation via Time-series Scholarly Topic Analysis and Publication Prior Analysis</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Zhuoren</forename><surname>Jiang</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">TCDL Bulletin</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">9</biblScope>\\n\\t\\t\\t<date type=\"published\" when=\"2013\">2013. 2013</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b21\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Cross-language Citation Recommendation via Publication Content and Citation Representation Fusion</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Zhuoren</forename><surname>Jiang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yao</forename><surname>Lu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xiaozhong</forename><surname>Liu</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 18th ACM/IEEE Joint Conference on Digital Libraries (JCDL\\'18</title>\\n\\t\\t\\t\\t<meeting>the 18th ACM/IEEE Joint Conference on Digital Libraries (JCDL\\'18</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"347\" to=\"348\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b22\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Crosslanguage Citation Recommendation via Hierarchical Representation Learning on Heterogeneous Graph</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Zhuoren</forename><surname>Jiang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yue</forename><surname>Yin</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Liangcai</forename><surname>Gao</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yao</forename><surname>Lu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xiaozhong</forename><surname>Liu</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR 2018</title>\\n\\t\\t\\t\\t<meeting><address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018-07-08\">2018. July 08-12. 2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"635\" to=\"644\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b23\">\\n\\t<monogr>\\n\\t\\t<title level=\"m\" type=\"main\">The STM report, an overview of scientific and scholarly publishing</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">A</forename><surname>Mabe</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">M</forename><surname>Johnson</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">R</forename><surname>Watkinson</surname></persName>\\n\\t\\t</author>\\n\\t\\t<ptr target=\"www.stm-assoc.org/2018_10_04_STM_Report_2018.pdf\"/>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018. 2018</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b24\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">A Scalable Hybrid Research Paper Recommender System for Microsoft Academic</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Anshul</forename><surname>Kanakia</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Zhihong</forename><surname>Shen</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Darrin</forename><surname>Eide</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Kuansan</forename><surname>Wang</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the The World Wide Web Conference (WWW\\'19</title>\\n\\t\\t\\t\\t<meeting>the The World Wide Web Conference (WWW\\'19</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2019\">2019</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"2893\" to=\"2899\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b25\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Utilizing Context in Generative Bayesian Models for Linked Corpus</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Saurabh</forename><surname>Kataria</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Prasenjit</forename><surname>Mitra</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Sumit</forename><surname>Bhatia</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI\\'10</title>\\n\\t\\t\\t\\t<meeting>the 24th AAAI Conference on Artificial Intelligence (AAAI\\'10</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2010\">2010</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"1340\" to=\"1345\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b26\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Citation Recommendation Using Distributed Representation of Discourse Facets in Scientific Articles</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yuta</forename><surname>Kobayashi</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Masashi</forename><surname>Shimbo</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yuji</forename><surname>Matsumoto</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 18th ACM/IEEE on Joint Conference on Digital Libraries (JCDL \\'18</title>\\n\\t\\t\\t\\t<meeting>the 18th ACM/IEEE on Joint Conference on Digital Libraries (JCDL \\'18</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"243\" to=\"251\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b27\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Distributed Representations of Sentences and Documents</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">V</forename><surname>Quoc</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Tomas</forename><surname>Le</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><surname>Mikolov</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 31th International Conference on Machine Learning</title>\\n\\t\\t\\t\\t<meeting>the 31th International Conference on Machine Learning<address><addrLine>Beijing, China</addrLine></address></meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2014-06\">2014. 2014. June 2014</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"1188\" to=\"1196\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b28\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Fulltext based Context-Rich Heterogeneous Network Mining Approach for Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xiaozhong</forename><surname>Liu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yingying</forename><surname>Yu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Chun</forename><surname>Guo</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yizhou</forename><surname>Sun</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Liangcai</forename><surname>Gao</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the Joint Conference on Digital Libraries</title>\\n\\t\\t\\t\\t<meeting>the Joint Conference on Digital Libraries</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2014\">2014</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"361\" to=\"370\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b29\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">On the recommending of citations for research papers</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Sean</forename><forename type=\"middle\">M</forename><surname>Mcnee</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Istvan</forename><surname>Albert</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Dan</forename><surname>Cosley</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Prateep</forename><surname>Gopalkrishnan</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">K</forename><surname>Shyong</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Al</forename><forename type=\"middle\">Mamunur</forename><surname>Lam</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Joseph</forename><forename type=\"middle\">A</forename><surname>Rashid</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">John</forename><surname>Konstan</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><surname>Riedl</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the ACM 2002 Conference on Computer Supported Cooperative (CSCW\\'02</title>\\n\\t\\t\\t\\t<meeting>the ACM 2002 Conference on Computer Supported Cooperative (CSCW\\'02</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2002\">2002</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"116\" to=\"125\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b30\">\\n\\t<monogr>\\n\\t\\t<title level=\"m\" type=\"main\">Distributed Representations of Words and Phrases and their Compositionality</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Tomas</forename><surname>Mikolov</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Ilya</forename><surname>Sutskever</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Kai</forename><surname>Chen</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Greg</forename><surname>Corrado</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Jeffrey</forename><surname>Dean</surname></persName>\\n\\t\\t</author>\\n\\t\\t<idno type=\"arXiv\">arXiv:1310.4546</idno>\\n\\t\\t<ptr target=\"http://arxiv.org/abs/1310.4546\"/>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2013\">2013. 2013</date>\\n\\t\\t\\t<biblScope unit=\"page\">4546</biblScope>\\n\\t\\t</imprint>\\n\\t</monogr>\\n\\t<note>CoRR abs/1310</note>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b31\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Combining aspects of genetic algorithms with weighted recommender hybridization</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Juergen</forename><surname>Mueller</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 19th International Conference on Information Integration and Web-based Applications &amp; Services (iiWAS\\'17</title>\\n\\t\\t\\t\\t<meeting>the 19th International Conference on Information Integration and Web-based Applications &amp; Services (iiWAS\\'17</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2017\">2017</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"13\" to=\"22\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b32\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Improving Document Ranking with Dual Word Embeddings</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Eric</forename><forename type=\"middle\">T</forename><surname>Nalisnick</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Bhaskar</forename><surname>Mitra</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Nick</forename><surname>Craswell</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Rich</forename><surname>Caruana</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 25th International Conference on World Wide Web (WWW\\'16</title>\\n\\t\\t\\t\\t<meeting>the 25th International Conference on World Wide Web (WWW\\'16</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2016\">2016</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"83\" to=\"84\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b33\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Joint latent topic models for text and citations</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Ramesh</forename><surname>Nallapati</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Amr</forename><surname>Ahmed</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Eric</forename><forename type=\"middle\">P</forename><surname>Xing</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">William</forename><forename type=\"middle\">W</forename><surname>Cohen</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD\\'08</title>\\n\\t\\t\\t\\t<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD\\'08</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2008\">2008</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"542\" to=\"550\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b34\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">A Supervised Learning Method for Context-Aware Citation Recommendation in a Large Corpus</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Lior</forename><surname>Rokach</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Prasenjit</forename><surname>Mitra</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Saurabh</forename><surname>Kataria</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Wenyi</forename><surname>Huang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Lee</forename><surname>Giles</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the Large-Scale and Distributed Systems for Information Retrieval Workshop (LSDS-IR\\'13</title>\\n\\t\\t\\t\\t<meeting>the Large-Scale and Distributed Systems for Information Retrieval Workshop (LSDS-IR\\'13</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2013\">2013</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"17\" to=\"22\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b35\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Bibliometric-Enhanced arXiv: A Data Set for Paper-Based and Citation-Based Tasks</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Tarek</forename><surname>Saier</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Michael</forename><surname>F&#228;rber</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 8th International Workshop on Bibliometric-enhanced Information Retrieval (BIR\\'19</title>\\n\\t\\t\\t\\t<meeting>the 8th International Workshop on Bibliometric-enhanced Information Retrieval (BIR\\'19</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2019\">2019</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"14\" to=\"26\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b36\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">An Overview of Microsoft Academic Service (MAS) and Applications</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Arnab</forename><surname>Sinha</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Zhihong</forename><surname>Shen</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yang</forename><surname>Song</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Hao</forename><surname>Ma</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Darrin</forename><surname>Eide</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Bo-June Paul</forename><surname>Hsu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Kuansan</forename><surname>Wang</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 24th International Conference on World Wide Web (WWW\\'15</title>\\n\\t\\t\\t\\t<meeting>the 24th International Conference on World Wide Web (WWW\\'15</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2015\">2015</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"243\" to=\"246\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b37\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Recommending citations for academic papers</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Trevor</forename><surname>Strohman</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">W</forename><forename type=\"middle\">Bruce</forename><surname>Croft</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">David</forename><forename type=\"middle\">D</forename><surname>Jensen</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR\\'07</title>\\n\\t\\t\\t\\t<meeting>the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR\\'07</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2007\">2007</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"705\" to=\"706\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b38\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Cross-language Contextaware Citation Recommendation in Scientific Articles</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xuewei</forename><surname>Tang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xiaojun</forename><surname>Wan</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xun</forename><surname>Zhang</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 37th International Conference on Research and Development in Information Retrieval (SIGIR \\'14</title>\\n\\t\\t\\t\\t<meeting>the 37th International Conference on Research and Development in Information Retrieval (SIGIR \\'14</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2014\">2014</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"817\" to=\"826\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b39\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">A LSTM Based Model for Personalized Context-Aware Citation Recommendation</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Libin</forename><surname>Yang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Yu</forename><surname>Zheng</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xiaoyan</forename><surname>Cai</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Hang</forename><surname>Dai</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Dejun</forename><surname>Mu</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Lantian</forename><surname>Guo</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Tao</forename><surname>Dai</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">IEEE Access</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">6</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"59618\" to=\"59627\"/>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018. 2018</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b40\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Personalized Citation Recommendation via Convolutional Neural Networks</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Jun</forename><surname>Yin</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xiaoming</forename><surname>Li</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the First International Joint Conference on Web and Big Data (APWeb-WAIM\\'17</title>\\n\\t\\t\\t\\t<meeting>the First International Joint Conference on Web and Big Data (APWeb-WAIM\\'17</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2017\">2017</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"285\" to=\"293\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b41\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">SemCiR: A citation recommendation system based on a novel semantic distance measure</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Fattane</forename><surname>Zarrinkalam</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Mohsen</forename><surname>Kahani</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Program</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">47</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"92\" to=\"112\"/>\\n\\t\\t\\t<date type=\"published\" when=\"2013\">2013. 2013</date>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b42\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">A Novel Personalized Citation Recommendation Approach Based on GAN</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Ye</forename><surname>Zhang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Libin</forename><surname>Yang</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Xiaoyan</forename><surname>Cai</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName><forename type=\"first\">Hang</forename><surname>Dai</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the 24th International Symposium on Foundations of Intelligent Systems (ISMIS\\'18</title>\\n\\t\\t\\t\\t<meeting>the 24th International Symposium on Foundations of Intelligent Systems (ISMIS\\'18</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2018\">2018</date>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"268\" to=\"278\"/>\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n\\t\\t\\t\\t</listBibl>\\n\\t\\t\\t</div>\\n\\t\\t</back>\\n\\t</text>\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etree.tostring(root[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91951ef2-8d02-4b3b-81bd-bbabcb5dc59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
